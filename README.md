# TCKR

**Text-Conditioned Knowledge Recycling (TCKR):**  
A Synthetic Dataset Generation Pipeline for High-Performing and Privacy-Preserving Image Classifiers


## Overview

This work introduces TCKR, a novel pipeline to generate synthetic datasets that achieve high utility for image classification while enhancing privacy protection. Addressing challenges like data scarcity, privacy issues, and dataset biases, TCKR leverages text-conditioned diffusion models to produce informative synthetic data. The pipeline integrates several components:
- **Stable Diffusion 2.0 (SD2):** Employed as a high-quality generator.
- **Low-Rank Adaptation (LoRA):** For efficient Stable Diffusion fine-tuning.
- **Dynamic Captioning with BLIP-2:** To capture instance-specific visual attributes.
- **Generative Knowledge Distillation (GKD):** To improve the informativeness of synthetic samples.

Comprehensive experiments across 12 diverse datasets have shown that classifiers trained on synthetic data generated by TCKR (i.e., the *Students*) can achieve accuracy comparable to - and in some cases exceeding - that of those trained on real data (i.e., the *Teachers*). Moreover, these classifiers demonstrate a significant increase in resilience against Membership Inference Attacks (as measured by the AUC<sub>MIA</sub>) and substantial improvements in the Accuracy Over Privacy (AOP) metric.

For more details, please refer to the full [MSc Thesis](https://www.politesi.polimi.it/item/preview.htm?uuid=6724f43f-b60a-4b1d-83ab-34a3a6136976) this work is based on.

![Student vs Teacher](images/student_vs_teacher.png)


## Repository Structure

- `src/`: Source code for all phases of TCKR.
- `lora_sd2/`: LoRA weights for the SD2 models fine-tuned on each real training dataset.
- `prompts/`: Prompts used for LoRA SD2 fine-tuning (in `original_order/`) and for synthetic training dataset generation (in `grouped_by_class/`).
- `trained_mbnv3/`: Weights of the MobileNetV3 Teachers (in `teachers/`) and Students (in `students/`) classifiers, trained on the Real Dataset and the generated Synthetic Dataset, respectively. The Synthetic Dataset has a cardinality of 20× the corresponding Real Dataset, except for Caltech101, where 10× was used due to its higher classification accuracy compared to 20×.
- `images/`: Images used in the README.
- `requirements.txt`: All Python dependencies needed for the project.


## Installation

1. **Clone the repository:**

   ```bash
   git clone <repository_url>
   cd TCKR
   ```

2. **Create and activate a new virtual environment:**

   ```bash
   python3 -m venv venv
   source venv/bin/activate # On Windows use: venv\Scripts\activate
   ```

3. **Install the required dependencies:**

   ```bash
    pip install -r requirements.txt
    ```


## Usage

1. **Run [run_evaluate.ipynb](src/run_evaluate.ipynb)** to evaluate the classification performance of the MobileNetV3 Teachers and Students, **after setting the needed parameters** (commented in the notebook).

2. **Run [mia_lira.ipynb](src/mia_lira.ipynb)** to conduct a Membership Inference Attack (MIA) on a trained MobileNetV3 classifier, using the Likelihood Ratio Attack (LiRA), **after setting the needed parameters** (commented in the notebook).
