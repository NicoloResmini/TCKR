{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Synthetic Cardinality for each Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Data from tables\n",
    "datasets = [\n",
    "    'CIFAR10', 'CIFAR100', 'Oxford-IIIT-Pet', 'TinyImageNet', \n",
    "    'StanfordCars', 'Food101', 'STL10', 'Imagewoof', 'Imagenette', 'Caltech101'\n",
    "]\n",
    "\n",
    "# Cardinality values\n",
    "cardinalities = [0.1, 0.2, 1, 5, 10, 20]\n",
    "cardinality_labels = ['0.1×', '0.2×', '1×', '5×', '10×', '20×']\n",
    "\n",
    "# AUC_MIA values (Table 5) - lower is better for privacy\n",
    "auc_mia_values = [\n",
    "    [52.03, 51.53, 52.53, 52.33, 53.03, 52.81],  # CIFAR10\n",
    "    [51.00, 52.54, 54.26, 59.24, 61.15, 62.80],  # CIFAR100\n",
    "    [50.97, 50.59, 56.13, 61.33, 63.09, 64.60],  # Oxford-IIIT-Pet\n",
    "    [51.02, 51.45, 52.66, 61.90, 63.70, 64.55],  # TinyImageNet\n",
    "    [55.00, 55.42, 65.61, 75.34, 78.03, 79.44],  # StanfordCars\n",
    "    [51.06, 51.21, 51.61, 55.62, 57.08, 58.90],  # Food101\n",
    "    [52.67, 52.57, 52.22, 55.99, 56.84, 58.38],  # STL10\n",
    "    [51.58, 52.76, 53.94, 55.86, 55.51, 55.82],  # Imagewoof\n",
    "    [54.55, 54.26, 54.68, 55.20, 55.01, 55.32],  # Imagenette\n",
    "    [57.84, 60.53, 56.44, 60.29, 60.60, 58.37],  # Caltech101\n",
    "]\n",
    "\n",
    "# AOP values (Table 6) - higher is better for combined accuracy/privacy\n",
    "aop_values = [\n",
    "    [83.37, 87.06, 86.48, 88.45, 86.41, 87.25],  # CIFAR10\n",
    "    [68.41, 69.34, 70.15, 60.50, 57.02, 54.35],  # CIFAR100\n",
    "    [76.96, 82.44, 73.27, 62.39, 59.30, 56.72],  # Oxford-IIIT-Pet\n",
    "    [64.01, 65.93, 67.09, 49.54, 46.82, 45.73],  # TinyImageNet\n",
    "    [24.82, 44.12, 47.97, 38.51, 36.09, 34.86],  # StanfordCars\n",
    "    [68.49, 73.41, 79.20, 69.92, 66.54, 62.54],  # Food101\n",
    "    [81.64, 83.81, 86.87, 76.69, 74.38, 70.68],  # STL10\n",
    "    [82.92, 81.35, 78.11, 73.88, 74.88, 74.23],  # Imagewoof\n",
    "    [79.86, 81.49, 80.91, 80.00, 80.70, 79.92],  # Imagenette\n",
    "    [41.28, 47.25, 71.93, 63.44, 63.05, 67.95],  # Caltech101\n",
    "]\n",
    "\n",
    "# CAS values from previous table (for comparison)\n",
    "cas_values = [\n",
    "    [90.28, 92.47, 95.45, 96.89, 97.20, 97.33],  # CIFAR10\n",
    "    [71.17, 76.56, 82.61, 84.93, 85.28, 85.74],  # CIFAR100\n",
    "    [79.98, 84.40, 92.34, 93.87, 94.41, 94.68],  # Oxford-IIIT-Pet\n",
    "    [66.65, 69.81, 74.42, 75.92, 76.00, 76.22],  # TinyImageNet\n",
    "    [30.03, 54.20, 82.60, 87.44, 87.90, 88.00],  # StanfordCars\n",
    "    [71.42, 77.01, 84.38, 86.52, 86.72, 86.93],  # Food101\n",
    "    [90.59, 92.65, 94.76, 96.16, 96.12, 96.36],  # STL10\n",
    "    [88.24, 90.58, 90.91, 92.21, 92.29, 92.52],  # Imagewoof\n",
    "    [95.06, 95.97, 96.76, 97.50, 97.68, 97.83],  # Imagenette\n",
    "    [55.24, 69.25, 91.65, 92.24, 92.62, 92.60],  # Caltech101\n",
    "]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create a dataframe-like structure for easier manipulation\n",
    "dataset_optimal = []\n",
    "for i, dataset in enumerate(datasets):\n",
    "    # Find best cardinality for each metric\n",
    "    best_auc_idx = np.argmin(auc_mia_values[i])  # Lower is better for AUC_MIA\n",
    "    best_aop_idx = np.argmax(aop_values[i])      # Higher is better for AOP\n",
    "    best_cas_idx = np.argmax(cas_values[i])      # Higher is better for CAS\n",
    "    \n",
    "    dataset_optimal.append({\n",
    "        'dataset': dataset,\n",
    "        'best_auc_card': cardinality_labels[best_auc_idx],\n",
    "        'best_aop_card': cardinality_labels[best_aop_idx],\n",
    "        'best_cas_card': cardinality_labels[best_cas_idx],\n",
    "        'best_auc_val': auc_mia_values[i][best_auc_idx],\n",
    "        'best_aop_val': aop_values[i][best_aop_idx],\n",
    "        'best_cas_val': cas_values[i][best_cas_idx]\n",
    "    })\n",
    "\n",
    "# Use the default dataset ordering\n",
    "default_order = datasets\n",
    "\n",
    "# Create arrays for the plot\n",
    "x = np.arange(len(default_order))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "\n",
    "# Create arrays for the plot in default order\n",
    "best_auc_indices = [cardinality_labels.index(dataset_optimal[i]['best_auc_card']) for i in range(len(datasets))]\n",
    "best_aop_indices = [cardinality_labels.index(dataset_optimal[i]['best_aop_card']) for i in range(len(datasets))]\n",
    "best_cas_indices = [cardinality_labels.index(dataset_optimal[i]['best_cas_card']) for i in range(len(datasets))]\n",
    "\n",
    "# Introduce a vertical offset (e.g. 0.2) to all bar heights\n",
    "offset = 0.2\n",
    "best_auc_indices_offset = [val + offset for val in best_auc_indices]\n",
    "best_aop_indices_offset = [val + offset for val in best_aop_indices]\n",
    "best_cas_indices_offset = [val + offset for val in best_cas_indices]\n",
    "\n",
    "# Create bars for optimal cardinality by metric\n",
    "bar1 = ax.bar(x - width, best_auc_indices_offset, width, label='Best AUC$_{MIA}$', color='green', alpha=0.7)\n",
    "bar2 = ax.bar(x, best_aop_indices_offset, width, label='Best AOP', color='blue', alpha=0.7)\n",
    "bar3 = ax.bar(x + width, best_cas_indices_offset, width, label='Best CAS', color='red', alpha=0.7)\n",
    "\n",
    "# Enable y-axis ticks and labels\n",
    "ax.tick_params(axis='y', which='both', left=True, labelleft=True)\n",
    "ax.set_yticks([i + offset for i in range(len(cardinality_labels))])\n",
    "ax.set_yticklabels(cardinality_labels)\n",
    "ax.set_ylabel('Synthetic Dataset Cardinality', fontsize=16)\n",
    "\n",
    "# Add x-axis ticks with default dataset names\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(default_order, fontsize=12, rotation=45)\n",
    "\n",
    "# And add the legend for the three metrics:\n",
    "ax.legend(fontsize=12, loc='best')\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "#plt.title('Optimal Cardinality for Each Metric', fontweight='bold', fontsize=22, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/metrics_best_cardinality.png', bbox_inches='tight', dpi=600) # do not move after plt.show() or it will save a blank image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student-Teacher Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Extract data from the table\n",
    "datasets = [\n",
    "    'CIFAR10', 'CIFAR100', 'Oxford-IIIT-Pet', 'TinyImageNet', 'StanfordCars', \n",
    "    'Food101', 'STL10', 'Imagewoof', 'Imagenette', 'Caltech101'\n",
    "]\n",
    "\n",
    "# Accuracy (higher is better)\n",
    "teacher_accuracy = [97.52, 85.49, 93.96, 75.67, 88.22, 86.79, 96.74, 93.05, 98.29, 92.26]\n",
    "student_accuracy = [97.33, 85.74, 94.68, 76.22, 88.00, 86.93, 96.36, 92.52, 97.83, 92.62]\n",
    "\n",
    "# AUC_MIA (lower is better)\n",
    "teacher_auc_mia = [53.89, 70.32, 72.74, 70.29, 82.53, 65.63, 65.89, 58.67, 60.32, 67.81]\n",
    "student_auc_mia = [52.81, 62.80, 64.60, 64.55, 79.44, 58.90, 58.38, 55.82, 55.32, 60.60]\n",
    "\n",
    "# AOP (higher is better)\n",
    "teacher_aop = [83.95, 43.22, 44.40, 38.29, 32.38, 50.37, 55.71, 67.58, 67.53, 50.16]\n",
    "student_aop = [87.25, 54.35, 56.72, 45.73, 34.86, 62.64, 70.68, 74.23, 79.92, 63.05]\n",
    "\n",
    "# Create a DataFrame for easier data manipulation\n",
    "df = pd.DataFrame({\n",
    "    'Dataset': datasets * 3,\n",
    "    'Metric': ['Accuracy'] * len(datasets) + ['AUC_MIA'] * len(datasets) + ['AOP'] * len(datasets),\n",
    "    'Teacher': teacher_accuracy + teacher_auc_mia + teacher_aop,\n",
    "    'Student': student_accuracy + student_auc_mia + student_aop,\n",
    "})\n",
    "\n",
    "# Calculate the differences (Student - Teacher)\n",
    "df['Difference'] = df['Student'] - df['Teacher']\n",
    "\n",
    "# For AUC_MIA, we invert the difference because lower is better\n",
    "df.loc[df['Metric'] == 'AUC_MIA', 'Difference'] = -df.loc[df['Metric'] == 'AUC_MIA', 'Difference']\n",
    "\n",
    "# Desired order for plotting\n",
    "df['Metric'] = pd.Categorical(df['Metric'], categories=['Accuracy', 'AUC_MIA', 'AOP'])\n",
    "\n",
    "# Set the style for all plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('muted')\n",
    "colors = sns.color_palette()\n",
    "\n",
    "###########################################################################################################################################\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Create a 3x1 grid for subplots (one for each metric)\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 18), sharex=True)\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "metrics = ['Accuracy', 'AUC_MIA', 'AOP']\n",
    "titles = ['Classification Accuracy', \n",
    "          'AUC$_{MIA}$', \n",
    "          'AOP']\n",
    "ylabels = ['Classification Accuracy', 'AUC$_{MIA}$', 'AOP']\n",
    "\n",
    "# Use the default order (no sorting)\n",
    "sorted_indices = {}\n",
    "sorted_indices['Accuracy'] = np.arange(len(teacher_accuracy))\n",
    "sorted_indices['AUC_MIA'] = np.arange(len(teacher_auc_mia))\n",
    "sorted_indices['AOP'] = np.arange(len(teacher_aop))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Get the sorted indices for this metric\n",
    "    idx = sorted_indices[metric]\n",
    "    \n",
    "    # Get the relevant data\n",
    "    if metric == 'Accuracy':\n",
    "        teacher_vals = [teacher_accuracy[j] for j in idx]\n",
    "        student_vals = [student_accuracy[j] for j in idx]\n",
    "        datasets_sorted = [datasets[j] for j in idx]\n",
    "    elif metric == 'AUC_MIA':\n",
    "        teacher_vals = [teacher_auc_mia[j] for j in idx]\n",
    "        student_vals = [student_auc_mia[j] for j in idx]\n",
    "        datasets_sorted = [datasets[j] for j in idx]\n",
    "    else:  # AOP\n",
    "        teacher_vals = [teacher_aop[j] for j in idx]\n",
    "        student_vals = [student_aop[j] for j in idx]\n",
    "        datasets_sorted = [datasets[j] for j in idx]\n",
    "    \n",
    "    # Set the positions and width for the bars\n",
    "    pos = np.arange(len(datasets_sorted))\n",
    "    width = 0.30\n",
    "    \n",
    "    # Create the bars\n",
    "    teacher_bars = ax.bar(pos - width/2, teacher_vals, width, label='Teacher Classifier', \n",
    "                        color=colors[0], alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "    student_bars = ax.bar(pos + width/2, student_vals, width, label='Student Classifier', \n",
    "                         color=colors[1], alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Calculate differences for annotations\n",
    "    diffs = np.array(student_vals) - np.array(teacher_vals)\n",
    "    \n",
    "    # Add difference annotations\n",
    "    for j, (p, diff) in enumerate(zip(pos, diffs)):\n",
    "        if metric == 'AUC_MIA':\n",
    "            # For AUC_MIA, negative diff is better (lower AUC_MIA is better)\n",
    "            color = 'green' if diff < 0 else 'red'\n",
    "            diff_text = f\"{diff:-.2f}\"  # Negate to show as improvement\n",
    "        else:\n",
    "            # For Accuracy and AOP, positive diff is better\n",
    "            color = 'green' if diff > 0 else 'red'\n",
    "            diff_text = f\"{diff:+.2f}\"\n",
    "        \n",
    "        ax.annotate(diff_text, \n",
    "                    xy=(p, max(teacher_vals[j], student_vals[j]) + 0.5), \n",
    "                    ha='center', va='bottom', \n",
    "                    color=color, fontweight='bold', fontsize=13)\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels\n",
    "    ax.set_ylabel(ylabels[i], fontsize=16)\n",
    "    ax.set_title(titles[i], fontsize=20, fontweight='bold')\n",
    "    ax.set_xticks(pos)\n",
    "    ax.set_xticklabels(datasets_sorted, rotation=45, ha='right', fontsize=13)\n",
    "    \n",
    "    # Add grid for easier reading\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add a horizontal line for reference\n",
    "    if metric == 'AUC_MIA':\n",
    "        ax.axhline(y=50, color='gray', linestyle='--', alpha=0.5)  # 50% is random guess\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('student_vs_teacher.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
